{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import mido\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "import keras\n",
    "import random\n",
    "import music21\n",
    "import glob\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Args: mido.mido_obj\n",
    "# output notelist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_notelist(mido_obj, res=8, note_range=(36,84)):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        res (int) - resolution.  8 is eighth notes, 4 quarter, etc...\n",
    "        note_range (tuple) - middle C = 60\n",
    "    \"\"\"\n",
    "\n",
    "    # this gives # of ticks in a column of the piano sheet\n",
    "    tick_step = round(float(mido_obj.ticks_per_beat/res))\n",
    "\n",
    "    active_notes = [0] * abs(np.diff(note_range)[0])\n",
    "\n",
    "    counter = 0\n",
    "    notelist = []\n",
    "\n",
    "    rawmsgs = [msg for track in mido_obj.tracks for msg in track]\n",
    "\n",
    "    # have to reset counter when a new track is detected\n",
    "    for msg in rawmsgs:\n",
    "        if msg.type not in set(['note_on','note_off']):\n",
    "            continue\n",
    "\n",
    "        #counter += ceil(msg.time/tick_step)\n",
    "        counter += msg.time\n",
    "\n",
    "        if msg.type == 'note_on' and msg.velocity > 0:        \n",
    "            active_notes[msg.note - note_range[0]] = counter\n",
    "\n",
    "        elif msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0):\n",
    "            # fill everything up to this with 1s\n",
    "            start = active_notes[msg.note - note_range[0]]  #round this section\n",
    "\n",
    "            notelist.append((msg.note, int(ceil(start/tick_step)), int(ceil((counter-start)/tick_step))))\n",
    "            active_notes[msg.note - note_range[0]] = 0\n",
    "\n",
    "    notelist = sorted(notelist, key=lambda x: x[1])\n",
    "    return (counter, notelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_musicmat(notelist, steps, note_range=(36,84)):\n",
    "    \"\"\" turns a notelist into a musicmat object\n",
    "    \"\"\"\n",
    "    music_mat = np.zeros([steps, int(np.diff(note_range))])\n",
    "    cnt = 0\n",
    "    for nt in notelist:\n",
    "        c = range(nt[1], (nt[2] + nt[1]))\n",
    "        r = [nt[0] - note_range[0]] * len(c)\n",
    "        music_mat[c,r] = np.array([1] * len(r) )\n",
    "        cnt += 1\n",
    "    return music_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segmentize(musicmat, maxlen, step):\n",
    "    \"\"\" Converts a musicmat matrix into \n",
    "    a 3D matrix with slices of length maxlen\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    steps = musicmat.shape[0]\n",
    "    for ix in range(0, steps-maxlen-1, step):\n",
    "        end = ix + maxlen\n",
    "        X.append(musicmat[ix:end:1, :])\n",
    "        y.append(musicmat[end+1,:])\n",
    "    X = np.stack(X)\n",
    "    y = np.stack(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#params\n",
    "\n",
    "res = 8\n",
    "note_range=(36,84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "\n",
    "guitar_dir = 'data/tr_guitar_licks/'\n",
    "for fname in glob.glob(guitar_dir + '*'):\n",
    "    try:\n",
    "        midifile = mido.MidiFile(fname)\n",
    "        counter, notelist = get_notelist(midifile)\n",
    "        tick_step = round(float(midifile.ticks_per_beat/res))\n",
    "        steps = int(ceil(counter/tick_step))\n",
    "        music_mat = make_musicmat(notelist, steps)\n",
    "        raw_data.append(music_mat)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine readable inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = 50\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for sample in raw_data:\n",
    "    smpX, smpy = segmentize(sample, maxlen, 1)\n",
    "    X.append(smpX)\n",
    "    y.append(smpy)\n",
    "\n",
    "X = np.concatenate(X, axis=0)\n",
    "y = np.concatenate(y, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnotes = np.diff(note_range)[0]\n",
    "maxlen = 50\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, nnotes)))\n",
    "model.add(Dense(nnotes))\n",
    "model.add(Dense(nnotes))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, nnotes)))\n",
    "model.add(Dense(nnotes))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16989/16989 [==============================] - 16s - loss: 4.2758    \n",
      "Epoch 2/10\n",
      "16989/16989 [==============================] - 15s - loss: 3.7675    \n",
      "Epoch 3/10\n",
      "16989/16989 [==============================] - 15s - loss: 3.5406    \n",
      "Epoch 4/10\n",
      "16989/16989 [==============================] - 15s - loss: 3.3112    \n",
      "Epoch 5/10\n",
      "16989/16989 [==============================] - 15s - loss: 3.1039    \n",
      "Epoch 6/10\n",
      "16989/16989 [==============================] - 15s - loss: 2.9127    \n",
      "Epoch 7/10\n",
      "16989/16989 [==============================] - 15s - loss: 2.7596    \n",
      "Epoch 8/10\n",
      "16989/16989 [==============================] - 15s - loss: 2.6361    \n",
      "Epoch 9/10\n",
      "16989/16989 [==============================] - 15s - loss: 2.5277    \n",
      "Epoch 10/10\n",
      "16989/16989 [==============================] - 15s - loss: 2.4448    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa63ed42550>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = X.astype(bool)\n",
    "model.fit(X,y, batch_size=50, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model.json','w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(X, open('X.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
