{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import mido\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "import keras\n",
    "import random\n",
    "import music21\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transpose(score, newkey='C'):\n",
    "    \"\"\" Transposes the midi file to C. \n",
    "    Args: music21.stream.Score\n",
    "    Returns: music21.stream.Score\n",
    "    \"\"\"\n",
    "\n",
    "    keys = {'C':0, \n",
    "            'C#':1, \n",
    "            'D-':1,\n",
    "            'D':2,\n",
    "            'D#':3,\n",
    "            'E-':3,\n",
    "            'E':4,\n",
    "            'F-':4,\n",
    "            'E#':5,        \n",
    "            'F':5,\n",
    "            'F#':6,\n",
    "            'G-':6,\n",
    "            'G':7,\n",
    "            'G#':8,\n",
    "            'A-':8,\n",
    "            'A':9,\n",
    "            'A#':10,\n",
    "            'B-':10,\n",
    "            'B':11,\n",
    "            'B#':0,\n",
    "           }\n",
    "\n",
    "    oldkey = score.analyze('key')\n",
    "\n",
    "    if oldkey.mode == \"major\":\n",
    "        halfSteps = keys[oldkey.tonic.name.upper()]\n",
    "\n",
    "    elif oldkey.mode == \"minor\":\n",
    "        halfSteps = keys[oldkey.tonic.name.upper()] + 4\n",
    "\n",
    "    halfSteps %= 12\n",
    "\n",
    "    newscore = score.transpose(-halfSteps)\n",
    "    trans_key = newscore.analyze('key')\n",
    "    print oldkey, trans_key\n",
    "    return newscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twin = mido.MidiFile('data/twinkle.mid')\n",
    "twin2 = mido.MidiFile('data/twinkle_twinkle.mid')\n",
    "simp = mido.MidiFile('data/simple_test.mid')\n",
    "simp2 = mido.MidiFile('data/simple_test_2notes.mid')\n",
    "song = mido.MidiFile('data/bags_groove_jh.mid')\n",
    "mond = mido.MidiFile('data/mond_3.mid')\n",
    "abba = mido.MidiFile('data/ABBA_-_Dancing_Queen.mid')\n",
    "bach = mido.MidiFile('data/bach_variations_sn.mid')\n",
    "cop = mido.MidiFile('data/appspg13.mid')\n",
    "chords = mido.MidiFile('deeplearningnet/data/Nottingham/train/ashover_simple_chords_1.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format\n",
    "\n",
    "midi -> notelist -> music_mat -> music_mat -> notelist -> midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = music21.converter.parse('data/twinkle.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the notelist (note, start, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates notelist - a list for all the notes\n",
    "\n",
    "midifile = chords\n",
    "\n",
    "# note_list = (note, start, duration)\n",
    "# have to address if notes are not perfectly inside a tick_step\n",
    "\n",
    "resolution = 8 # eighth notes\n",
    "\n",
    "# this gives # of ticks in a column of the piano sheet\n",
    "tick_step = round(float(midifile.ticks_per_beat/resolution))\n",
    "\n",
    "note_range = (20, 90)\n",
    "active_notes = [0] * abs(np.diff(note_range)[0])\n",
    "\n",
    "counter = 0\n",
    "notelist = []\n",
    "\n",
    "rawmsgs = [msg for track in midifile.tracks for msg in track]\n",
    "\n",
    "# have to reset counter when a new track is detected\n",
    "for msg in rawmsgs:\n",
    "    if msg.type not in set(['note_on','note_off']):\n",
    "        continue\n",
    "    \n",
    "    #counter += ceil(msg.time/tick_step)\n",
    "    counter += msg.time\n",
    "    \n",
    "    if msg.type == 'note_on' and msg.velocity > 0:        \n",
    "        active_notes[msg.note - note_range[0]] = counter\n",
    "        \n",
    "    elif msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0):\n",
    "        # fill everything up to this with 1s\n",
    "        start = active_notes[msg.note - note_range[0]]  #round this section\n",
    "               \n",
    "        notelist.append((msg.note, int(ceil(start/tick_step)), int(ceil((counter-start)/tick_step))))\n",
    "        active_notes[msg.note - note_range[0]] = 0\n",
    "\n",
    "notelist = sorted(notelist, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = int(ceil(counter/tick_step))\n",
    "music_mat = np.zeros([steps, int(np.diff(note_range))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the music_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for nt in notelist:\n",
    "    c = range(nt[1], (nt[2] + nt[1]))\n",
    "    r = [nt[0] - note_range[0]] * len(c)\n",
    "    music_mat[c,r] = np.array([1] * len(r) )\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing the matrix into X,y into a 3D matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 50 * 2\n",
    "nnotes = np.diff(note_range)[0]\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X= []\n",
    "y = []\n",
    "for ix in range(0, steps-maxlen-1, step):\n",
    "    end = ix + maxlen\n",
    "    X.append(music_mat[ix:end:1, :])\n",
    "    y.append(music_mat[end+1,:])\n",
    "X = np.stack(X)\n",
    "y = np.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, nnotes)))\n",
    "model.add(Dense(nnotes))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1391/1391 [==============================] - 3s - loss: 8.2900     \n",
      "Epoch 1/1\n",
      "1391/1391 [==============================] - 0s - loss: 7.0379     \n",
      "Epoch 1/1\n",
      "1391/1391 [==============================] - 0s - loss: 6.4306     \n",
      "Epoch 1/1\n",
      "1391/1391 [==============================] - 0s - loss: 5.9572     \n",
      "Epoch 1/1\n",
      "1391/1391 [==============================] - 0s - loss: 5.6943     \n",
      "Epoch 1/1\n",
      "1391/1391 [==============================] - 0s - loss: 5.5403     \n",
      "Epoch 1/1\n",
      "1391/1391 [==============================] - 0s - loss: 5.1264     \n",
      "Epoch 1/1\n",
      "1391/1391 [==============================] - 0s - loss: 5.0427     \n",
      "Epoch 1/1\n",
      "1391/1391 [==============================] - 0s - loss: 4.9516     \n",
      "Epoch 1/1\n",
      "1391/1391 [==============================] - 0s - loss: 4.9501     \n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "for _ in range(10):\n",
    "    res = model.fit(X, y, batch_size=128, nb_epoch=1)\n",
    "    loss.extend(res.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating new tunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsteps = 100\n",
    "\n",
    "start_ix = random.randint(0, steps-maxlen - 1)\n",
    "psg_seed = music_mat[start_ix:start_ix+maxlen,:]\n",
    "x = psg_seed[None,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_song = []\n",
    "new_song.append(x)\n",
    "\n",
    "for _ in range(tsteps):\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "\n",
    "    # this is a timestep slice\n",
    "    new_note = np.zeros(nnotes)\n",
    "    new_note[preds.argmax()] = 1\n",
    "    new_note = new_note[None, None,:]\n",
    "\n",
    "    # redo the seed psg\n",
    "    psg = np.concatenate([x,new_note], axis=1)\n",
    "    x = psg[:, 1:,:]\n",
    "\n",
    "    new_song.append(new_note)\n",
    "\n",
    "new_song = np.concatenate(new_song, axis=1)\n",
    "new_song = np.squeeze(new_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song rolls to midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mido import Message, MidiFile, MidiTrack\n",
    "\n",
    "mid = MidiFile()\n",
    "mid.tracks.append(track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music mat to notelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_notes = np.array([0] * abs(np.diff(note_range)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track = MidiTrack()\n",
    "nsteps = new_song.shape[0]\n",
    "last_event = 0\n",
    "for ix in range(nsteps):\n",
    "    step_slice = new_song[ix,:]\n",
    "    \n",
    "    diff = [ix for ix,(x,y) in enumerate(zip(step_slice, active_notes)) if x!=y]\n",
    "    if len(diff) == 0:\n",
    "        last_event += 1\n",
    "        continue\n",
    "\n",
    "    # this means there is a difference\n",
    "    for note_ix in diff:\n",
    "        # off to on\n",
    "        note = note_ix+min(note_range)\n",
    "        if active_notes[note_ix] == 0:\n",
    "            track.append(Message('note_on', note=note, velocity=127, time=int(tick_step*last_event) ))\n",
    "            active_notes[note_ix] = 1\n",
    "        else:\n",
    "            track.append(Message('note_off', note=note, velocity=127, time=int(tick_step*last_event)))\n",
    "            active_notes[note_ix] = 0\n",
    "        last_event = 0        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the file\n",
    "mid = MidiFile()\n",
    "mid.tracks.append(track)\n",
    "mid.save('new_song.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test[np.array([0,2])] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "coords = np.nonzero(new_song)\n",
    "track = MidiTrack()\n",
    "\n",
    "time = 0\n",
    "for ix,note in zip(*coords):\n",
    "    if ix == note:\n",
    "        track.append(Message('note_on', note=note+min(note_range), velocity=127, time=0))\n",
    "        active_notes[note] = True\n",
    "    elif ix != note:\n",
    "        active_idx = [idx for idx,y in enumerate(active_notes) if y]\n",
    "\n",
    "        if len(active_idx) > 0:\n",
    "            track.append(Message('note_off', note=active_idx[0], velocity=127, time=int((ix-time)*tick_step)))    \n",
    "        for idx in active_idx[1:]:\n",
    "            track.append(Message('note_off', note=idx, velocity=127, time=0))\n",
    "        \n",
    "        active_notes = [False] * abs(np.diff(note_range)[0])\n",
    "        track.append(Message('note_on', note=note, velocity=127, time=0))\n",
    "        active_notes[note] = True\n",
    "    time = ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
